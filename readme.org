High dimensional computing is a great way to explore neuromorphic, neurosymbolic computing paradigms.


* Sparse Binary Vectors

Brain networks exhibit sparse pattern activity, which is the motivation to explore high dimensional computing with sparse vectors.
Sparse VSA architectures have been show to have competitive capacity and desirable HDC properties.[fn:1]
At the same time, they have drastically reduced memory consumption.


Blog post:


** Code

Following the paper [[https://www.researchgate.net/publication/299535938_High-Dimensional_Computing_with_Sparse_Vectors][High-Dimensional Computing with Sparse Vectors]] [Laiho,Poikonen,Kanerva,Lehtonen 2020].

[[file:src/bennischwerdtner/hd/binary_sparse_segmented.clj][binary_sparse_segmented.clj]] contains an implementation of 'Binary Sparse Distributed Representation with segments' (naming from [Schlegel et.al. 2021][fn:1]).

** Examples

[[file:./examples][examples]] contains examples and expirements.

*** What Is The Dollar In Mexico?

The implementation succesfully represents the analogy-reasoning example from Kanerva ([[*3]]):

#+begin_src clojure

    (def mexico-record
      (h/thin
       (h/bundle
        (h/bind (symbol->hv :capital) (symbol->hv 'mxc))
        (h/bind (symbol->hv :currency) (symbol->hv 'peso))
        (h/bind (symbol->hv :name) (symbol->hv 'mex)))))

    (def usa-record
      (h/thin (h/bundle (h/bind (symbol->hv :capital)
                                (symbol->hv 'wdc))
                        (h/bind (symbol->hv :currency)
                                (symbol->hv 'dollar))
                        (h/bind (symbol->hv :name)
                                (symbol->hv 'usa)))))


    (let [result
          (h/unbind mexico-record
                    ;; this represents the query
                    (h/unbind usa-record (symbol->hv 'dollar)))]

      (cleanup-lookup-value result))
  ;;  => peso

#+end_src


* Future

Dynamic sparsity mechanisms could perhaps represent different /levels of detail/, or parallel search processes[fn:2].

* Literatrue

** 1

Laiho et.al. 2015
High-Dimensional Computing with Sparse Vectors
https://www.researchgate.net/publication/299535938_High-Dimensional_Computing_with_Sparse_Vectors


** 2

Schlegel et.al. 2021  A comparison of Vector Symbolic Architectures

http://www.arxiv.org/abs/2001.11797
arXiv:2001.11797

** 3

Pentti Kanerva. Hyperdimensional computing: An introduction to computing in distributed representation with
high-dimensional random vectors. Cognitive Computation, 1(2):139â€“159, 2009. doi:10.1007/s12559-009-9009-8.


This is really amazing, deep computing analysis, properties of HDC made intuitive, and Kanerva writes down the algebra for why the examples of work:

Talk versions (they are at most appetizers for the book chapter above):

- https://youtu.be/1g5VEcnG6fI?si=lC9xAKZEL0hzKk3A
- https://youtu.be/zUCoxhExe0o?si=KOQ5gkSHvI5DMOm3



* Footnotes

[fn:2]

G. Palm Neural Assemblies: An Alternative Approach to Artificial Intelligence, (first edition: 1982, 2nd ed.: 2022)



[fn:1]

Schlegel et.al. 2021  A comparison of Vector Symbolic Architectures

http://www.arxiv.org/abs/2001.11797
arXiv:2001.11797
