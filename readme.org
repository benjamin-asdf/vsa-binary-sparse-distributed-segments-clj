High dimensional computing is a great approach to neuromorphic, neurosymbolic computing.


* Sparse Binary Vectors

Brain networks exhibit sparse pattern activity, which is the motivation to explore high dimensional computing with sparse vectors.
Sparse VSA architectures have been show to have competitive capacity and desirable HDC properties.[fn:1]
At the same time, they have drastically reduced memory consumption.

Blog post:


** Code

Following the paper [[https://www.researchgate.net/publication/299535938_High-Dimensional_Computing_with_Sparse_Vectors][High-Dimensional Computing with Sparse Vectors]] [Laiho,Poikonen,Kanerva,Lehtonen 2020].

[[file:src/bennischwerdtner/hd/binary_sparse_segmented.clj][binary_sparse_segmented.clj]] contains an implementation of 'Binary Sparse Distributed Representation with segments' (naming from [[*2]])

** Examples

[[file:./examples][examples]] contains examples and expirements.

*** What Is The Dollar In Mexico?

The implementation succesfully represents the analogy-reasoning example from Kanerva ([[*3]]):

#+begin_src clojure

    (def mexico-record
      (h/thin
       (h/bundle
        (h/bind (symbol->hv :capital) (symbol->hv 'mxc))
        (h/bind (symbol->hv :currency) (symbol->hv 'peso))
        (h/bind (symbol->hv :name) (symbol->hv 'mex)))))

    (def usa-record
      (h/thin (h/bundle (h/bind (symbol->hv :capital)
                                (symbol->hv 'wdc))
                        (h/bind (symbol->hv :currency)
                                (symbol->hv 'dollar))
                        (h/bind (symbol->hv :name)
                                (symbol->hv 'usa)))))


    (let [result
          (h/unbind mexico-record
                    ;; this represents the query
                    (h/unbind usa-record (symbol->hv 'dollar)))]

      (cleanup-lookup-value result))
  ;;  => peso

#+end_src

*** 'prototype'

Keys and values are interchangeable in VSA. We might as well call them /prototypes/. We might not need variables at all.
As analogy, a child might learn the prototype 'mum', which is first used as a symbol for a single person.
Later, 'mum' could augment, into a symbol representing the =role= mum.
I.e. you use the mum prototype as key in records.

*** Hyper-If

[[file:./examples/hyper_if.clj]]

#+begin_src clojure

    ;; Idea 1:
    ;;
    ;; A hyper if
    ;; In high dimensional computing, the outcome of a calculation could represent
    ;; the combination of all 'possible' outcomes.
    ;;
    ;; Interesting here to note is that 'what is possible?' is defined by the threshold, too.
    ;;
    ;; We can imagine dynamically lowering and increasing the threshold.
    ;; (Would model something like 'fast' and 'slow' thinking perhaps).
    ;;


  ;; a hyper-if evaluates to the information mix of all 'possible' branches.

  (def both-true-and-false
    (hd/thin
     (hd/bundle
      (->prototype true)
      (->prototype false))))

  (defn coin
    []
    (hyper-if both-true-and-false
              (->prototype :heads)
              (->prototype :tails)))

  ;; all the bookeeping can go away ofc
  (map :k (cleanup-lookup-verbose (coin)))

  ;; => (:heads :tails)

#+end_src

We can envisage a programming paradigm that models something like a multiverse, where multiple things are true.
(This is probably very close to /probabilistic programming/, I know little of that).

Similarly, a =multi-symbol= could resolve to either a list of things, or to a thing representing the set of things.

* Acknowledgements

Thanks to [[https://github.com/gigasquid/vsa-clj][Carin Meier's intro to VSA]].

Thanks to [[https://github.com/cnuernber/dtype-next][Chris Nuernberger's dtype next]] for high performance and linear algebra stuff at the clojure repl.

* Notice


* Future

- Dynamic sparsity mechanisms could perhaps represent different /levels of detail/, or parallel search processes[fn:2].

- Implement a Sparse Distributed Memory, or figure out how to use an existing one

* Literatrue

** 1

Laiho et.al. 2015
High-Dimensional Computing with Sparse Vectors
https://www.researchgate.net/publication/299535938_High-Dimensional_Computing_with_Sparse_Vectors

** 2

Schlegel et.al. 2021  A comparison of Vector Symbolic Architectures

http://www.arxiv.org/abs/2001.11797
arXiv:2001.11797

** 3

Pentti Kanerva. Hyperdimensional computing: An introduction to computing in distributed representation with
high-dimensional random vectors. Cognitive Computation, 1(2):139â€“159, 2009. doi:10.1007/s12559-009-9009-8.


This is really amazing, deep computing analysis, properties of HDC made intuitive, and Kanerva writes down the algebra for why the examples of work:

Talk versions (they are at most appetizers for the book chapter above):

- https://youtu.be/1g5VEcnG6fI?si=lC9xAKZEL0hzKk3A
- https://youtu.be/zUCoxhExe0o?si=KOQ5gkSHvI5DMOm3

* Footnotes

[fn:1]

Schlegel et.al. 2021  A comparison of Vector Symbolic Architectures

http://www.arxiv.org/abs/2001.11797
arXiv:2001.11797

[fn:2]

G. Palm Neural Assemblies: An Alternative Approach to Artificial Intelligence, (first edition: 1982, 2nd ed.: 2022)
